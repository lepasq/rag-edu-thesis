{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FqeieOC5vUB"
      },
      "source": [
        "# Evaluating the Ideal Chunk Size for a RAG System using LlamaIndex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIvSXj365r2n"
      },
      "source": [
        "# **Introduction**\n",
        "\n",
        "Retrieval-augmented generation (RAG) has introduced an innovative approach that fuses the extensive retrieval capabilities of search systems with the LLM. When implementing a RAG system, one critical parameter that governs the system’s efficiency and performance is the `chunk_size`. How does one discern the optimal chunk size for seamless retrieval? This is where LlamaIndex `Response Evaluation` comes handy. In this blogpost, we'll guide you through the steps to determine the best `chunk size` using LlamaIndex’s `Response Evaluation` module. If you're unfamiliar with the `Response` Evaluation module, we recommend reviewing its [documentation](https://docs.llamaindex.ai/en/latest/core_modules/supporting_modules/evaluation/modules.html) before proceeding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpbtWrEa53Ct"
      },
      "source": [
        "## **Why Chunk Size Matters**\n",
        "\n",
        "Choosing the right `chunk_size` is a critical decision that can influence the efficiency and accuracy of a RAG system in several ways:\n",
        "\n",
        "1. **Relevance and Granularity**: A small `chunk_size`, like 128, yields more granular chunks. This granularity, however, presents a risk: vital information might not be among the top retrieved chunks, especially if the `similarity_top_k` setting is as restrictive as 2. Conversely, a chunk size of 512 is likely to encompass all necessary information within the top chunks, ensuring that answers to queries are readily available. To navigate this, we employ the Faithfulness and Relevancy metrics. These measure the absence of ‘hallucinations’ and the ‘relevancy’ of responses based on the query and the retrieved contexts respectively.\n",
        "2. **Response Generation Time**: As the `chunk_size` increases, so does the volume of information directed into the LLM to generate an answer. While this can ensure a more comprehensive context, it might also slow down the system. Ensuring that the added depth doesn't compromise the system's responsiveness is crucial.\n",
        "\n",
        "In essence, determining the optimal `chunk_size` is about striking a balance: capturing all essential information without sacrificing speed. It's vital to undergo thorough testing with various sizes to find a configuration that suits the specific use-case and dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SR8jlf3358_z"
      },
      "source": [
        "## **Setup**\n",
        "\n",
        "Before embarking on the experiment, we need to ensure all requisite modules are imported:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ItNWVKRRD67j"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: llama-index in /home/addo/.local/lib/python3.11/site-packages (0.10.7)\n",
            "Requirement already satisfied: llama-index-embeddings-openai in /home/addo/.local/lib/python3.11/site-packages (0.1.3)\n",
            "Requirement already satisfied: spacy in /home/addo/.local/lib/python3.11/site-packages (3.7.4)\n",
            "Requirement already satisfied: llama-index-embeddings-huggingface in /home/addo/.local/lib/python3.11/site-packages (0.1.1)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.2.0,>=0.1.0 in /home/addo/.local/lib/python3.11/site-packages (from llama-index) (0.1.1)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.0 in /home/addo/.local/lib/python3.11/site-packages (from llama-index) (0.10.7)\n",
            "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /home/addo/.local/lib/python3.11/site-packages (from llama-index) (0.9.48)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.0 in /home/addo/.local/lib/python3.11/site-packages (from llama-index) (0.1.2)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.0 in /home/addo/.local/lib/python3.11/site-packages (from llama-index) (0.1.1)\n",
            "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.0 in /home/addo/.local/lib/python3.11/site-packages (from llama-index) (0.1.2)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.0 in /home/addo/.local/lib/python3.11/site-packages (from llama-index) (0.1.1)\n",
            "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.0 in /home/addo/.local/lib/python3.11/site-packages (from llama-index) (0.1.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/addo/.local/lib/python3.11/site-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/addo/.local/lib/python3.11/site-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/addo/.local/lib/python3.11/site-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/addo/.local/lib/python3.11/site-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/addo/.local/lib/python3.11/site-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /home/addo/.local/lib/python3.11/site-packages (from spacy) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/addo/.local/lib/python3.11/site-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/addo/.local/lib/python3.11/site-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/addo/.local/lib/python3.11/site-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /home/addo/.local/lib/python3.11/site-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/addo/.local/lib/python3.11/site-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/addo/.local/lib/python3.11/site-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/addo/.local/lib/python3.11/site-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/lib/python3.11/site-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/addo/.local/lib/python3.11/site-packages (from spacy) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/lib/python3.11/site-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/lib/python3.11/site-packages (from spacy) (68.0.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/addo/.local/lib/python3.11/site-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/addo/.local/lib/python3.11/site-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /home/addo/.local/lib/python3.11/site-packages (from spacy) (1.26.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.0 in /home/addo/.local/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.20.2)\n",
            "Requirement already satisfied: torch<3.0.0,>=2.1.2 in /home/addo/.local/lib/python3.11/site-packages (from llama-index-embeddings-huggingface) (2.1.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.37.0 in /home/addo/.local/lib/python3.11/site-packages (from llama-index-embeddings-huggingface) (4.37.2)\n",
            "Requirement already satisfied: filelock in /usr/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.12.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/addo/.local/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2023.12.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/addo/.local/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.8.0)\n",
            "Requirement already satisfied: aiohttp in /home/addo/.local/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.9.3)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /home/addo/.local/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.0->llama-index) (2.0.27)\n",
            "Requirement already satisfied: dataclasses-json in /home/addo/.local/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index) (0.6.4)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /home/addo/.local/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /home/addo/.local/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index) (1.0.8)\n",
            "Requirement already satisfied: httpx in /home/addo/.local/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index) (0.26.0)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in /home/addo/.local/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index) (0.1.13)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/addo/.local/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /home/addo/.local/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index) (3.2.1)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /home/addo/.local/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index) (3.8.1)\n",
            "Requirement already satisfied: openai>=1.1.0 in /home/addo/.local/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index) (1.6.1)\n",
            "Requirement already satisfied: pandas in /home/addo/.local/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index) (2.1.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /home/addo/.local/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index) (9.0.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /home/addo/.local/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index) (8.2.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /home/addo/.local/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index) (0.5.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /home/addo/.local/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index) (0.9.0)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /home/addo/.local/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.0->llama-index) (4.12.3)\n",
            "Requirement already satisfied: bs4<0.0.3,>=0.0.2 in /home/addo/.local/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.0->llama-index) (0.0.2)\n",
            "Requirement already satisfied: pymupdf<2.0.0,>=1.23.21 in /home/addo/.local/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.0->llama-index) (1.23.24)\n",
            "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /home/addo/.local/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.0->llama-index) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/addo/.local/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/addo/.local/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/addo/.local/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: sympy in /home/addo/.local/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (1.12)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/addo/.local/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/addo/.local/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/addo/.local/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/addo/.local/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/addo/.local/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/addo/.local/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/addo/.local/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/addo/.local/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/addo/.local/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/addo/.local/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/addo/.local/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /home/addo/.local/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/addo/.local/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (12.3.101)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/lib/python3.11/site-packages (from transformers<5.0.0,>=4.37.0->llama-index-embeddings-huggingface) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/addo/.local/lib/python3.11/site-packages (from transformers<5.0.0,>=4.37.0->llama-index-embeddings-huggingface) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /home/addo/.local/lib/python3.11/site-packages (from transformers<5.0.0,>=4.37.0->llama-index-embeddings-huggingface) (0.4.1)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /home/addo/.local/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3.11/site-packages (from jinja2->spacy) (2.1.3)\n",
            "Requirement already satisfied: platformdirs in /usr/lib/python3.11/site-packages (from setuptools->spacy) (3.11.0)\n",
            "Requirement already satisfied: jaraco.text in /usr/lib/python3.11/site-packages (from setuptools->spacy) (3.11.1)\n",
            "Requirement already satisfied: more-itertools in /usr/lib/python3.11/site-packages (from setuptools->spacy) (10.1.0)\n",
            "Requirement already satisfied: ordered-set in /usr/lib/python3.11/site-packages (from setuptools->spacy) (4.1.0)\n",
            "Requirement already satisfied: tomli in /usr/lib/python3.11/site-packages (from setuptools->spacy) (2.0.1)\n",
            "Requirement already satisfied: validate-pyproject in /usr/lib/python3.11/site-packages (from setuptools->spacy) (0.13.post1.dev0+gb752273.d20230520)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/addo/.local/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/addo/.local/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/addo/.local/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/addo/.local/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /home/addo/.local/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.9.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.0->llama-index) (2.5)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /home/addo/.local/lib/python3.11/site-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.0->llama-index) (1.16.0)\n",
            "Requirement already satisfied: anyio in /home/addo/.local/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.0->llama-index) (4.2.0)\n",
            "Requirement already satisfied: certifi in /usr/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.0->llama-index) (2023.7.22)\n",
            "Requirement already satisfied: httpcore==1.* in /home/addo/.local/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.0->llama-index) (1.0.2)\n",
            "Requirement already satisfied: sniffio in /home/addo/.local/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.0->llama-index) (1.3.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /home/addo/.local/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.0->llama-index) (0.14.0)\n",
            "Requirement already satisfied: joblib in /home/addo/.local/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.0->llama-index) (1.3.2)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.0->llama-index) (1.8.0)\n",
            "Requirement already satisfied: PyMuPDFb==1.23.22 in /home/addo/.local/lib/python3.11/site-packages (from pymupdf<2.0.0,>=1.23.21->llama-index-readers-file<0.2.0,>=0.1.0->llama-index) (1.23.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /home/addo/.local/lib/python3.11/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.0->llama-index) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/addo/.local/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.0->llama-index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/addo/.local/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.0->llama-index) (3.20.2)\n",
            "Requirement already satisfied: jaraco.functools in /usr/lib/python3.11/site-packages (from jaraco.text->setuptools->spacy) (3.9.0)\n",
            "Requirement already satisfied: jaraco.context>=4.1 in /usr/lib/python3.11/site-packages (from jaraco.text->setuptools->spacy) (4.3.0)\n",
            "Requirement already satisfied: autocommand in /usr/lib/python3.11/site-packages (from jaraco.text->setuptools->spacy) (2.2.2)\n",
            "Requirement already satisfied: inflect in /usr/lib/python3.11/site-packages (from jaraco.text->setuptools->spacy) (7.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.0->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/addo/.local/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.0->llama-index) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /home/addo/.local/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.0->llama-index) (2023.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /home/addo/.local/lib/python3.11/site-packages (from sympy->torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (1.3.0)\n",
            "Requirement already satisfied: fastjsonschema<=3,>=2.16.2 in /usr/lib/python3.11/site-packages (from validate-pyproject->setuptools->spacy) (2.18.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.0->llama-index) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index llama-index-embeddings-openai spacy llama-index-embeddings-huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "y9SVm76h58de"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "from llama_index.core import (\n",
        "    SimpleDirectoryReader,\n",
        "    VectorStoreIndex,\n",
        "    ServiceContext,\n",
        ")\n",
        "from llama_index.core.evaluation import (\n",
        "    DatasetGenerator,\n",
        "    FaithfulnessEvaluator,\n",
        "    RelevancyEvaluator,\n",
        "    CorrectnessEvaluator\n",
        ")\n",
        "from llama_index.llms.openai import OpenAI\n",
        "\n",
        "import openai\n",
        "import time\n",
        "openai.api_key = ''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO21UssT6L8N"
      },
      "source": [
        "## **Load Data**\n",
        "\n",
        "Let’s load our document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "x6QdEBd-17OC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "319\n"
          ]
        }
      ],
      "source": [
        "# Load Data\n",
        "document_base_path = \"../data/web-software-development/\"\n",
        "\n",
        "def get_filepath_substring(file_path):\n",
        "    if document_base_path in file_path:\n",
        "        return file_path.split(document_base_path)[1]\n",
        "    return file_path\n",
        "\n",
        "# documents_path = f\"{document_base_path}21-working-with-databases/\" # single chapter\n",
        "documents_path = f\"{document_base_path}\" # full course\n",
        "\n",
        "reader = SimpleDirectoryReader(documents_path, recursive=True)\n",
        "\n",
        "documents = reader.load_data()\n",
        "print(len(documents))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnpPtiz56TYA"
      },
      "source": [
        "## **Question Generation**\n",
        "\n",
        "To select the right `chunk_size`, we'll compute metrics like Average Response time, Faithfulness, and Relevancy for various `chunk_sizes`. The `DatasetGenerator` will help us generate questions from the documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "26BgDF3L6Z0r"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Amount of documents:  319\n",
            "=== EVAL QUESTIONS AND ANSWERS ===\n",
            "[('Why use NoSQL instead of SQL?', 'They are designed to scale horizontally.'), ('What is the difference between authentication and authorization?', 'The term authentication refers to identifying a user. The term authorization refers to the process of verifying that the user has the rights to perform the actions that the user is trying to perform.'), ('What is a UUID?', 'UUIDs are a common way of identifying resources. They are 128-bit numbers that are designed for being unique without central coordination (i.e. a service that would keep track of which identifier to assign next).')]\n"
          ]
        }
      ],
      "source": [
        "# To evaluate for each chunk size, we will first generate a set of 40 questions from first 20 pages.\n",
        "# eval_documents = documents[:20]\n",
        "eval_documents = documents\n",
        "print(\"Amount of documents: \", len(eval_documents))\n",
        "\n",
        "# data_generator = DatasetGenerator.from_documents(documents)\n",
        "# eval_questions = data_generator.generate_questions_from_nodes(num = 40)\n",
        "\n",
        "# generated from above, hardcoded to save costs\n",
        "\n",
        "\n",
        "# TODO not representative of student queries\n",
        "# too generic / not comprehension\n",
        "# get data from chatbot\n",
        "\n",
        "\n",
        "gen_eval_questions = ['what is the importance of using a database in web applications?',\n",
        "                      'What database management system will be used in this course?',\n",
        "                      'What are the learning objectives related to working with databases?',\n",
        "                      'Where can you find a tutorial for SQL basics if you need a refresher?',\n",
        "                      'How can you start using PostgreSQL according to the document?',\n",
        "                      'What is the recommended approach for taking PostgreSQL into use for development?',\n",
        "                      #   'What is the purpose of the Walking skeleton in relation to PostgreSQL?',\n",
        "                      'What are some options for running PostgreSQL locally?',\n",
        "                      'Name two hosted services that provide PostgreSQL as a service.',\n",
        "                      #   'Why does the document strongly recommend using the first option for development when starting to use PostgreSQL?',\n",
        "                      'What are two options for starting to use PostgreSQL as mentioned in the document?',\n",
        "                      'What are some examples of hosted services that provide PostgreSQL databases?',\n",
        "                      #   'Why does the document strongly recommend using the first option for development?',\n",
        "                      'How can you get started with ElephantSQL according to the document?',\n",
        "                      \"What attributes are included in the table created in the document's example using SQL?\",\n",
        "                      'How can you add names to the table in ElephantSQL according to the document?',\n",
        "                      \"What SQL query can you use to select all rows from the 'names' table in ElephantSQL?\",\n",
        "                      \"What library is used in the document's example to access the database programatically?\",\n",
        "                      #   'What information is grayed out in the image of the ElephantSQL details page?',\n",
        "                      \"What is the purpose of the 'id' attribute in the table created in the document's example?\",\n",
        "                      #   'What library is used in the first example to access a PostgreSQL database in the provided code snippet?',\n",
        "                      #   'How can you specify the database credentials when using Postgres.js in the provided code snippet?',\n",
        "                      #   'What is the purpose of the `max: 2` parameter in the Postgres.js example?',\n",
        "                      #   'In the second example, what library is used to access a PostgreSQL database?',\n",
        "                      'What is the recommended alternative to Deno Postgres mentioned in the document?',\n",
        "                      #   'How can you establish a connection to a PostgreSQL database using Deno Postgres in the provided code snippet?',\n",
        "                      #   'What query is executed in the Deno Postgres example to retrieve data from the database?',\n",
        "                      'What is the significance of having a database client when working with databases?',\n",
        "                      'What is the default database client mentioned in the document for accessing a PostgreSQL database?',\n",
        "                      'Where can you find a list of PostgreSQL clients for different operating systems according to the document?',\n",
        "                      'What database driver is used when working with Deno and PostgreSQL in the provided document?',\n",
        "                      'How can you create a database client using the Postgres.js driver?',\n",
        "                      #   'In the example code provided, what SQL query is being executed to retrieve data from the database?',\n",
        "                      'How does Postgres.js ensure safe query generation when constructing SQL queries?',\n",
        "                      'What is the purpose of the `sql` function in the Postgres.js driver?',\n",
        "                      #   'In the example code, how is the result data iterated over to print only the name property?',\n",
        "                      #   'What SQL statement is used to insert data into a database in the provided document?',\n",
        "                      #   'After inserting a new name into the database, how many names are present in the database according to the output?',\n",
        "                      'What flag is required to be used with Deno when working with the Postgres.js driver?',\n",
        "                      'How can you access the Postgres.js documentation for further details on tagged template literals?']\n",
        "\n",
        "\n",
        "eval_qa = [\n",
        "    ('Why use NoSQL instead of SQL?',\n",
        "     'They are designed to scale horizontally.'),\n",
        "\n",
        "    ('What is the difference between authentication and authorization?',\n",
        "     'The term authentication refers to identifying a user. The term authorization refers to the process of verifying that the user has the rights to perform the actions that the user is trying to perform.'),\n",
        "\n",
        "    ('What is a UUID?',\n",
        "     'UUIDs are a common way of identifying resources. They are 128-bit numbers that are designed for being unique without central coordination (i.e. a service that would keep track of which identifier to assign next).'),\n",
        "]\n",
        "\n",
        "\n",
        "def get_page_number(path):\n",
        "    substr = get_filepath_substring(path)\n",
        "    chapter, section = substr.split(\"/\")\n",
        "    chapter_no = chapter.split(\"-\")[0]\n",
        "    section_no = section.split(\"-\")[0]\n",
        "    return chapter_no + section_no\n",
        "\n",
        "print(\"=== EVAL QUESTIONS AND ANSWERS ===\")\n",
        "print(eval_qa)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3WwA-0N6dMO"
      },
      "source": [
        "## Setting Up Evaluators\n",
        "\n",
        "We are setting up the GPT-4 model to serve as the backbone for evaluating the responses generated during the experiment. Two evaluators, `FaithfulnessEvaluator` and `RelevancyEvaluator`, are initialised with the `service_context` .\n",
        "\n",
        "1. **Faithfulness Evaluator** - It is useful for measuring if the response was hallucinated and measures if the response from a query engine matches any source nodes.\n",
        "2. **Relevancy Evaluator** - It is useful for measuring if the query was actually answered by the response and measures if the response + source nodes match the query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "G2LoMRtr6fnG"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at deepset/roberta-base-squad2 and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core import Settings\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "\n",
        "# We will use for evaluating the responses\n",
        "\n",
        "\n",
        "gpt35 = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
        "# gpt4 = OpenAI(model=\"gpt-4\", temperature=0.2)\n",
        "\n",
        "roberta = HuggingFaceEmbedding(model_name=\"deepset/roberta-base-squad2\")\n",
        "\n",
        "\n",
        "def get_openai_text_embedding_3_large(chunk_size):\n",
        "    return OpenAIEmbedding(model=\"text-embedding-3-large\", chunk_size=chunk_size,)\n",
        "\n",
        "def get_openai_text_embedding_3_small(chunk_size):\n",
        "    return OpenAIEmbedding(model=\"text-embedding-3-small\", chunk_size=chunk_size,)\n",
        "\n",
        "def get_openai_text_embedding_ada_002(chunk_size):\n",
        "    return OpenAIEmbedding(model=\"text-embedding-ada-002\", chunk_size=chunk_size,)\n",
        "\n",
        "def get_roberta_text_embedding():\n",
        "    return roberta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_365174/3108636645.py:4: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
            "  service_context_gpt_35 = ServiceContext.from_defaults(llm=llm_evaluate)\n"
          ]
        }
      ],
      "source": [
        "llm_evaluate = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
        "\n",
        "# Define service context for llm evaluation\n",
        "service_context_gpt_35 = ServiceContext.from_defaults(llm=llm_evaluate)\n",
        "\n",
        "# Define Faithfulness and Relevancy Evaluators\n",
        "faithfulness_gpt = FaithfulnessEvaluator(\n",
        "    service_context=service_context_gpt_35)\n",
        "relevancy_gpt = RelevancyEvaluator(service_context=service_context_gpt_35)\n",
        "correctness_gpt = CorrectnessEvaluator(service_context=service_context_gpt_35)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# (DO NOT RUN) Debugging local embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from llama_index.core import Settings\n",
        "\n",
        "# from llama_index.core.schema import IndexNode\n",
        "# from llama_index.core import (\n",
        "#     load_index_from_storage,\n",
        "#     StorageContext,\n",
        "#     VectorStoreIndex,\n",
        "# )\n",
        "# from llama_index.core.node_parser import SentenceSplitter\n",
        "# from llama_index.core import SummaryIndex\n",
        "# from llama_index.core.retrievers import RecursiveRetriever\n",
        "# import os\n",
        "# # from tqdm.notebook import tqdm\n",
        "# import pickle\n",
        "\n",
        "\n",
        "# def build_index_local(docs, chunk_size, out_path: str):\n",
        "#     print(\"Chunk size: \", chunk_size)\n",
        "\n",
        "#     Settings.embed_model = embed_model\n",
        "\n",
        "#     nodes = []\n",
        "\n",
        "#     splitter = SentenceSplitter(\n",
        "#         chunk_size=chunk_size, chunk_overlap=chunk_size/4)\n",
        "#     for idx, doc in enumerate(docs):\n",
        "#         print('Splitting: ' + str(idx))\n",
        "\n",
        "#         cur_nodes = splitter.get_nodes_from_documents([doc])\n",
        "#         for cur_node in cur_nodes:\n",
        "#             # ID will be base + parent\n",
        "#             file_path = doc.metadata[\"file_path\"].split(document_base_path)[1]\n",
        "#             new_node = IndexNode(\n",
        "#                 text=cur_node.text or \"None\",\n",
        "#                 index_id=str(file_path),\n",
        "#                 metadata=doc.metadata,\n",
        "#                 # obj=doc\n",
        "#             )\n",
        "#             nodes.append(new_node)\n",
        "        \n",
        "\n",
        "#         # Debugging\n",
        "#         print(len(cur_nodes), len(str(doc)), len(str(cur_nodes[0])))\n",
        "#         for xyz in cur_nodes:\n",
        "#             print(xyz)\n",
        "#             print(\"-\")\n",
        "#         print()\n",
        "#         print(\"----DOC-----\")\n",
        "#         print(doc)\n",
        "\n",
        "#         print()\n",
        "#         print()\n",
        "\n",
        "#     print(\"num nodes: \" + str(len(nodes)))\n",
        "\n",
        "#     service_context = ServiceContext.from_defaults(\n",
        "#         llm=llm_evaluate, embed_model=embed_model)\n",
        "\n",
        "#     # save index to disk\n",
        "#     if not os.path.exists(out_path):\n",
        "#         index = VectorStoreIndex(nodes, service_context=service_context)\n",
        "#         index.set_index_id(\"simple_index\")\n",
        "#         index.storage_context.persist(f\"./{out_path}\")\n",
        "#     else:\n",
        "#         # rebuild storage context\n",
        "#         storage_context = StorageContext.from_defaults(\n",
        "#             persist_dir=f\"./{out_path}\"\n",
        "#         )\n",
        "#         # load index\n",
        "#         index = load_index_from_storage(\n",
        "#             storage_context, index_id=\"simple_index\", service_context=service_context\n",
        "#             # storage_context, index_id=\"simple_index\", embed_model=embed_model\n",
        "#         )\n",
        "\n",
        "#     return index\n",
        "\n",
        "\n",
        "# # build_index_local(eval_documents, 1024, \"Test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# vs. Storing embeddings (Weaviate)\n",
        "`docker-compose -f docker-compose.weaviate-persistent.yml up`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# text-embedding-3-large with 128 chunk size -> W128te3l\n",
        "# W because has to start with capital letter\n",
        "def get_full_course_index(chunk_size, model_name):\n",
        "    return f\"W{chunk_size}{''.join([x[0] for x in model_name.split('-')])}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/addo/.local/lib/python3.11/site-packages/weaviate/warnings.py:121: DeprecationWarning: Dep005: You are using weaviate-client version 3.26.2. The latest version is 4.5.1.\n",
            "            Please consider upgrading to the latest version. See https://weaviate.io/developers/weaviate/client-libraries/python for details.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.core import Settings\n",
        "\n",
        "from llama_index.core.schema import IndexNode\n",
        "from llama_index.core import (\n",
        "    load_index_from_storage,\n",
        "    StorageContext,\n",
        "    VectorStoreIndex,\n",
        ")\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.core import SummaryIndex\n",
        "from llama_index.core.retrievers import RecursiveRetriever\n",
        "import os\n",
        "# from tqdm.notebook import tqdm\n",
        "import pickle\n",
        "\n",
        "import weaviate\n",
        "from llama_index.vector_stores.weaviate import WeaviateVectorStore\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "client = weaviate.Client(\"http://localhost:8080\")\n",
        "\n",
        "\n",
        "def build_index(docs, chunk_size, embed_model):\n",
        "    print(\"Chunk size: \", chunk_size)\n",
        "\n",
        "    Settings.embed_model = embed_model\n",
        "\n",
        "    service_context = ServiceContext.from_defaults(\n",
        "        llm=llm_evaluate, embed_model=embed_model)\n",
        "\n",
        "    index_name = get_full_course_index(chunk_size, embed_model.model_name)\n",
        "\n",
        "    # save index to disk if does not exist\n",
        "    if not client.schema.exists(index_name):\n",
        "        print(f\"Schema {index_name} does not exist, rebuilding and then storing in db\")\n",
        "        nodes = []\n",
        "        splitter = SentenceSplitter(\n",
        "            chunk_size=chunk_size, chunk_overlap=chunk_size/4)\n",
        "        for idx, doc in enumerate(docs):\n",
        "            print('Splitting: ' + str(idx))\n",
        "\n",
        "            cur_nodes = splitter.get_nodes_from_documents([doc])\n",
        "            for cur_node in cur_nodes:\n",
        "                # ID will be base + parent\n",
        "                file_path = get_filepath_substring(doc.metadata[\"file_path\"])\n",
        "                new_node = IndexNode(\n",
        "                    text=cur_node.text or \"None\",\n",
        "                    index_id=str(file_path),\n",
        "                    metadata=doc.metadata,\n",
        "                    # obj=doc\n",
        "                )\n",
        "                nodes.append(new_node)\n",
        "\n",
        "        print(\"num nodes: \" + str(len(nodes)))\n",
        "\n",
        "        vector_store = WeaviateVectorStore(\n",
        "            weaviate_client=client, index_name=index_name\n",
        "        )\n",
        "        storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "        index = VectorStoreIndex(nodes, storage_context = storage_context, service_context=service_context)\n",
        "    else:\n",
        "        # load index\n",
        "        print(f\"Schema {index_name} exists already, load cached from database\")\n",
        "        vector_store = WeaviateVectorStore(\n",
        "            weaviate_client=client, index_name=index_name\n",
        "        )\n",
        "        index = VectorStoreIndex.from_vector_store(vector_store, service_context=service_context)\n",
        "\n",
        "    return index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "# <chunk_size>, <k>, <use_hybrid>, <model>, <use_rag>\n",
        "\n",
        "# config_lst = [(128, 10, True, gpt35, True), (128, 8, True, gpt35, True), (256, 6, True, gpt35, True),\n",
        "#  (512, 4, True, gpt35, True), (1024, 2, True, gpt35, True), (2048, 1, True, gpt35, True)]\n",
        "\n",
        "openai_3_128_large = get_openai_text_embedding_3_large(128)\n",
        "# openai_3_128_small = get_openai_text_embedding_3_small(128)\n",
        "openai_ada_002_128 = get_openai_text_embedding_ada_002(128)\n",
        "roberta = get_roberta_text_embedding()\n",
        "\n",
        "config_lst = [(128, 8, True, gpt35, True, openai_3_128_large), \n",
        "              (128, 8, True, gpt35, True, openai_ada_002_128), \n",
        "              (128, 8, True, gpt35, True, roberta), \n",
        "              (128, 8, False, gpt35, True, openai_3_128_large), \n",
        "              (128, 8, False, gpt35, True, openai_ada_002_128), \n",
        "              (128, 8, False, gpt35, True, roberta), \n",
        "              (128, 8, True, gpt35, False, openai_3_128_large),\n",
        "              ]\n",
        "\n",
        "n_runs = len(config_lst)\n",
        "\n",
        "answers = [[] for _ in range(n_runs)]\n",
        "sources = [[] for _ in range(n_runs)]\n",
        "source_docs = [[] for _ in range(n_runs)]\n",
        "\n",
        "time_scores = [[] for _ in range(n_runs)]\n",
        "faithfulness_scores = [[] for _ in range(n_runs)]\n",
        "relevancy_scores = [[] for _ in range(n_runs)]\n",
        "correctness_scores = [[] for _ in range(n_runs)]\n",
        "\n",
        "faithfulness_false = [[] for _ in range(n_runs)]\n",
        "relevancy_false = [[] for _ in range(n_runs)]\n",
        "correctness_false = [[] for _ in range(n_runs)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chunk size:  128\n",
            "Schema W128te3l exists already, load cached from database\n",
            "== BUILDING QUERY ENGINE ==\n",
            "== BUILDING CHAT ENGINE ==\n",
            "Chunk size:  128\n",
            "Schema W128tea0 exists already, load cached from database\n",
            "== BUILDING QUERY ENGINE ==\n",
            "== BUILDING CHAT ENGINE ==\n",
            "Chunk size:  128\n",
            "Schema W128dbs exists already, load cached from database\n",
            "== BUILDING QUERY ENGINE ==\n",
            "== BUILDING CHAT ENGINE ==\n",
            "Chunk size:  128\n",
            "Schema W128te3l exists already, load cached from database\n",
            "== BUILDING QUERY ENGINE ==\n",
            "== BUILDING CHAT ENGINE ==\n",
            "Chunk size:  128\n",
            "Schema W128tea0 exists already, load cached from database\n",
            "== BUILDING QUERY ENGINE ==\n",
            "== BUILDING CHAT ENGINE ==\n",
            "Chunk size:  128\n",
            "Schema W128dbs exists already, load cached from database\n",
            "== BUILDING QUERY ENGINE ==\n",
            "== BUILDING CHAT ENGINE ==\n",
            "Chunk size:  128\n",
            "Schema W128te3l exists already, load cached from database\n",
            "== BUILDING QUERY ENGINE ==\n",
            "== BUILDING CHAT ENGINE ==\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_365174/4074129552.py:29: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
            "  service_context = ServiceContext.from_defaults(\n"
          ]
        }
      ],
      "source": [
        "vector_indices = []\n",
        "query_engines = []\n",
        "chat_engines = []\n",
        "\n",
        "# Helper methods\n",
        "\n",
        "def build_query_engine(vector_index, similarity_top_k, is_hybrid, embed_model):\n",
        "    print(\"== BUILDING QUERY ENGINE ==\")\n",
        "    if is_hybrid:\n",
        "        return vector_index.as_query_engine(\n",
        "            similarity_top_k=similarity_top_k, embed_model=embed_model,\n",
        "            vector_store_query_mode=\"hybrid\", alpha=0.0  # BM25\n",
        "        )\n",
        "    # -- VEC ONLY --\n",
        "    return vector_index.as_query_engine(\n",
        "        similarity_top_k=similarity_top_k, embed_model=embed_model,\n",
        "    )\n",
        "\n",
        "\n",
        "def build_chat_engine(vector_index, similarity_top_k, is_hybrid, embed_model):\n",
        "    print(\"== BUILDING CHAT ENGINE ==\")\n",
        "    if is_hybrid:\n",
        "        return vector_index.as_chat_engine(\n",
        "            similarity_top_k=similarity_top_k, embed_model=embed_model,\n",
        "            vector_store_query_mode=\"hybrid\", alpha=0.0  # BM25\n",
        "        )\n",
        "    # -- VEC ONLY --\n",
        "    return vector_index.as_chat_engine(\n",
        "        similarity_top_k=similarity_top_k, embed_model=embed_model,\n",
        "    )\n",
        "\n",
        "def build_all_indices():\n",
        "    for run_i, (chunk_size, similarity_top_k, is_hybrid, llm, is_rag, embed_model) in enumerate(config_lst):\n",
        "        vector_index = build_index(eval_documents, chunk_size, embed_model) \n",
        "        vector_indices.append(vector_index)\n",
        "        query_engines.append(build_query_engine(vector_index, similarity_top_k, is_hybrid, embed_model))\n",
        "        chat_engines.append(build_chat_engine(vector_index, similarity_top_k, is_hybrid, embed_model))\n",
        "\n",
        "build_all_indices()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUncIIxR6gVz"
      },
      "source": [
        "## **Response Evaluation For A Chunk Size**\n",
        "\n",
        "We evaluate each chunk_size based on 3 metrics.\n",
        "\n",
        "1. Average Response Time.\n",
        "2. Average Faithfulness.\n",
        "3. Average Relevancy.\n",
        "\n",
        "Here's a function, `evaluate_config`, that does just that which has:\n",
        "\n",
        "1. VectorIndex Creation.\n",
        "2. Building the Query Engine**.**\n",
        "3. Metrics Calculation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "dEC2Lr0z6p1N"
      },
      "outputs": [],
      "source": [
        "# Define function to calculate average response time, average faithfulness and average relevancy metrics for given chunk size\n",
        "# We use GPT-3.5-Turbo to generate response and GPT-4 to evaluate it.\n",
        "from llama_index.core.base.response.schema import Response\n",
        "\n",
        "\n",
        "def evaluate_config(chunk_size, similarity_top_k, llm, run_i, embed_model, eval_qa=eval_qa, label=\"default\", is_hybrid=True, is_rag=True, is_chat=True):\n",
        "    \"\"\"\n",
        "    Evaluate the average response time, faithfulness, and relevancy of responses for a given chunk size.\n",
        "    \"\"\"\n",
        "\n",
        "    Settings.llm = llm\n",
        "    Settings.embed_model = embed_model\n",
        "\n",
        "    chat_engine = chat_engines[run_i]\n",
        "    query_engine = query_engines[run_i]\n",
        "    # Iterate over each question in eval_questions to compute metrics.\n",
        "    for q, a in eval_qa:\n",
        "        print(\"--Q: \", q)\n",
        "        start_time = time.time()\n",
        "\n",
        "        if is_rag:\n",
        "            if is_chat:\n",
        "                response_vector = chat_engine.chat(q)\n",
        "                raw_file_paths = list(set(value['file_path']\n",
        "                                        for value in response_vector.sources[0].raw_output.metadata.values()))\n",
        "                source_file_paths = list(\n",
        "                    map(get_filepath_substring, raw_file_paths))\n",
        "                source_docs[run_i].append(response_vector.source_nodes)\n",
        "\n",
        "            else:\n",
        "                response_vector = query_engine.query(q)\n",
        "\n",
        "                # get unique list of file paths of source docs\n",
        "                if response_vector.metadata is not None:\n",
        "                    print(\"--sources: \")\n",
        "                    raw_file_paths = list(set(value['file_path']\n",
        "                                            for value in response_vector.metadata.values()))\n",
        "                    source_file_paths = list(\n",
        "                        map(get_filepath_substring, raw_file_paths))\n",
        "                else:\n",
        "                    source_file_paths = []\n",
        "                source_docs[run_i].append(response_vector.get_formatted_sources)\n",
        "\n",
        "\n",
        "            print(\"--A: \", str(response_vector))\n",
        "            sources[run_i].append(source_file_paths)\n",
        "            print(\"----------\")\n",
        "\n",
        "\n",
        "        else: # NO RAG\n",
        "            # this seems to be the case with RAG systems\n",
        "            q += \" Make the answer one or two sentence long.\"\n",
        "            response_vector = None\n",
        "            response = str(OpenAI().complete(q))\n",
        "            print(\"--A: \", str(response))\n",
        "            response_vector = Response(response)\n",
        "            sources[run_i].append([])\n",
        "\n",
        "        answers[run_i].append(response_vector)\n",
        "\n",
        "        elapsed_time = time.time() - start_time\n",
        "\n",
        "        faithfulness_result = faithfulness_gpt.evaluate_response(\n",
        "            response=response_vector\n",
        "        ).passing if is_rag else False\n",
        "\n",
        "        relevancy_result = relevancy_gpt.evaluate_response(\n",
        "            query=q, response=response_vector\n",
        "        ).passing if is_rag else False\n",
        "\n",
        "        if not faithfulness_result:\n",
        "            faithfulness_false[run_i].append((q, str(response_vector)))\n",
        "        if not relevancy_result:\n",
        "            relevancy_false[run_i].append((q, str(response_vector)))\n",
        "\n",
        "        try:\n",
        "            correctness_result = correctness_gpt.evaluate(\n",
        "                query=q,\n",
        "                response=str(response_vector),\n",
        "                reference=a,\n",
        "            )\n",
        "            correctness_scores[run_i].append(\n",
        "                (correctness_result.score, correctness_result.feedback))\n",
        "            if correctness_result.score < 2.0:\n",
        "                correctness_false[run_i].append(\n",
        "                    (q, str(response_vector), (correctness_result.score, correctness_result.feedback)))\n",
        "        except:\n",
        "            print(\"Exception occured\")\n",
        "            correctness_scores[run_i].append(None)\n",
        "\n",
        "        time_scores[run_i].append(elapsed_time)\n",
        "        faithfulness_scores[run_i].append(faithfulness_result)\n",
        "        relevancy_scores[run_i].append(relevancy_result)\n",
        "        # print(\n",
        "        #     f\"t={elapsed_time}, f={faithfulness_result}, r={relevancy_result}, c={correctness_result.score}\\n-------\")\n",
        "\n",
        "    print(\"===========\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8DQvTP96s48"
      },
      "source": [
        "## **Testing Across Different Chunk Sizes**\n",
        "\n",
        "We'll evaluate a range of chunk sizes to identify which offers the most promising metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "jlKICwXH6Tib"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--Q:  Why use NoSQL instead of SQL?\n",
            "--A:  NoSQL databases are often chosen over SQL databases when dealing with unstructured or semi-structured data. They offer more flexibility in handling varying data types and structures, making them suitable for applications that require horizontal scalability and distributed data models. NoSQL databases are also preferred for real-time applications and scenarios that require rapid development and iteration.\n",
            "----------\n",
            "--Q:  What is the difference between authentication and authorization?\n",
            "--A:  Authentication is the process of verifying the identity of a user, ensuring that the user is who they claim to be. Authorization, on the other hand, is the process of determining what actions or resources a user is allowed to access after they have been authenticated. In simpler terms, authentication confirms identity, while authorization determines permissions and access rights.\n",
            "----------\n",
            "Exception occured\n",
            "--Q:  What is a UUID?\n",
            "--A:  A UUID, or Universally Unique Identifier, is a 128-bit number used to uniquely identify information or entities in computer systems. It is typically represented as a 32-character hexadecimal string, often separated by hyphens for readability. UUIDs are generated in a way that makes them highly unlikely to be duplicated, making them suitable for use as identifiers across different systems without the need for centralized coordination.\n",
            "----------\n",
            "===========\n",
            "--Q:  Why use NoSQL instead of SQL?\n",
            "--A:  NoSQL databases are often chosen over SQL databases when dealing with unstructured or semi-structured data, as they offer more flexibility in handling varying data types and structures. NoSQL databases are also preferred for their scalability and ability to handle large volumes of data efficiently, making them suitable for applications with high data variability and volume.\n",
            "----------\n",
            "Exception occured\n",
            "--Q:  What is the difference between authentication and authorization?\n",
            "--A:  Authentication is the process of verifying the identity of a user, ensuring that the user is who they claim to be. On the other hand, authorization is the process of determining what actions or resources a user is allowed to access after they have been authenticated. Authentication focuses on verifying identity, while authorization focuses on granting permissions based on that verified identity.\n",
            "----------\n",
            "--Q:  What is a UUID?\n",
            "--A:  A UUID is a universally unique identifier.\n",
            "----------\n",
            "===========\n",
            "--Q:  Why use NoSQL instead of SQL?\n",
            "--A:  NoSQL databases are often chosen over SQL databases when dealing with unstructured or rapidly changing data. They offer more flexibility in handling different data types and structures. Additionally, NoSQL databases can scale horizontally more easily, making them suitable for applications with high volumes of data and traffic.\n",
            "----------\n",
            "--Q:  What is the difference between authentication and authorization?\n",
            "--A:  Authentication is the process of verifying the identity of a user, ensuring that the user is who they claim to be. Authorization, on the other hand, is the process of determining what actions or resources a user is allowed to access after they have been authenticated.\n",
            "----------\n",
            "Exception occured\n",
            "--Q:  What is a UUID?\n",
            "--A:  A UUID, or Universally Unique Identifier, is a 128-bit number used to uniquely identify information or entities in computer systems. It is typically represented as a 32-character hexadecimal string, often separated by hyphens for readability. UUIDs are generated in such a way that they are highly unlikely to be duplicated, making them suitable for use in various scenarios where unique identification is required.\n",
            "----------\n",
            "Exception occured\n",
            "===========\n",
            "--Q:  Why use NoSQL instead of SQL?\n",
            "--A:  NoSQL databases are often chosen over SQL databases for their flexibility in handling unstructured or semi-structured data, scalability, and ability to handle large volumes of data efficiently. NoSQL databases are particularly suitable for applications where the data structure is not clearly defined or may evolve over time, allowing for easier adaptation to changing data requirements. Additionally, NoSQL databases are commonly used in distributed systems and cloud environments due to their horizontal scalability and fault tolerance capabilities.\n",
            "----------\n",
            "--Q:  What is the difference between authentication and authorization?\n",
            "--A:  Authentication is the process of identifying a user, typically by verifying their identity through various means like passwords or biometrics. On the other hand, authorization is the process of determining what actions a user is allowed to perform and what resources they can access after they have been authenticated. In simpler terms, authentication confirms who you are, while authorization determines what you can do.\n",
            "----------\n",
            "--Q:  What is a UUID?\n",
            "--A:  A UUID is a universally unique identifier, which is a 128-bit number used to uniquely identify information or entities in computer systems.\n",
            "----------\n",
            "===========\n",
            "--Q:  Why use NoSQL instead of SQL?\n",
            "--A:  NoSQL databases are often chosen over SQL databases due to concerns about scalability and the ability to handle large amounts of data. NoSQL databases are designed to scale horizontally and are schemaless, allowing for more flexibility in handling complex data models. Additionally, NoSQL databases offer features that were initially missing in relational databases, leading to their adoption in certain scenarios.\n",
            "----------\n",
            "--Q:  What is the difference between authentication and authorization?\n",
            "--A:  Authentication is the process of verifying a user's identity, typically through credentials like passwords. It confirms that the user is who they claim to be. On the other hand, authorization is the process of determining what actions a user is allowed to perform and what resources they can access after they have been authenticated. It focuses on defining access rights to specific resources within an application based on the user's identity and permissions.\n",
            "----------\n",
            "--Q:  What is a UUID?\n",
            "--A:  A UUID is a 128-bit number that serves as a unique identifier for resources. It is designed to be unique without requiring central coordination, meaning there is no need for a service to keep track of which identifier to assign next. UUIDs are standardized in RFC 4122 and are commonly used for identifying objects or entities in various systems.\n",
            "----------\n",
            "Exception occured\n",
            "===========\n",
            "--Q:  Why use NoSQL instead of SQL?\n",
            "--A:  NoSQL databases are often chosen over SQL databases for reasons such as their ability to handle unstructured or semi-structured data more efficiently, scalability for large amounts of data, flexibility in schema design, and better performance for certain types of applications like real-time analytics or content management systems.\n",
            "\n",
            "NoSQL databases are non-relational and do not require a fixed schema, allowing for flexible data models. SQL databases are relational and use structured query language for defining and manipulating data. NoSQL databases are horizontally scalable and can handle large amounts of unstructured data efficiently. SQL databases are vertically scalable and work well for complex queries and transactions. NoSQL databases are often used for big data and real-time applications, while SQL databases are commonly used in traditional business applications.\n",
            "----------\n",
            "--Q:  What is the difference between authentication and authorization?\n",
            "--A:  Authentication is the process of verifying the identity of a user, ensuring that the user is who they claim to be. It involves validating credentials such as usernames and passwords. On the other hand, authorization is the process of determining what actions a user is allowed to perform within a system or application after they have been authenticated. Authorization involves defining access levels and permissions for different users or user roles.\n",
            "----------\n",
            "--Q:  What is a UUID?\n",
            "--A:  A UUID, or Universally Unique Identifier, is a 128-bit number used to uniquely identify information or entities in computer systems. It is typically represented as a 32-character hexadecimal string, such as \"550e8400-e29b-41d4-a716-446655440000\". UUIDs are generated in a way that ensures uniqueness across space and time, making them suitable for identifying various types of data without the need for a centralized authority to coordinate the generation process.\n",
            "----------\n",
            "===========\n",
            "--Q:  Why use NoSQL instead of SQL?\n",
            "--A:  NoSQL databases are more flexible and scalable, making them better suited for handling large amounts of unstructured data and high traffic loads.\n",
            "Exception occured\n",
            "--Q:  What is the difference between authentication and authorization?\n",
            "--A:  Authentication is the process of verifying a user's identity, while authorization is the process of determining what actions a user is allowed to perform.\n",
            "Exception occured\n",
            "--Q:  What is a UUID?\n",
            "--A:  A UUID (Universally Unique Identifier) is a 128-bit number used to uniquely identify information in computer systems, ensuring no two items have the same identifier.\n",
            "Exception occured\n",
            "===========\n"
          ]
        }
      ],
      "source": [
        "from statistics import mean\n",
        "\n",
        "# Iterate over different chunk sizes to evaluate the metrics to help fix the chunk size.\n",
        "for run_i, (chunk_size, similarity_top_k, is_hybrid, llm, is_rag, embed_model) in enumerate(config_lst):\n",
        "    evaluate_config(chunk_size, similarity_top_k, llm, run_i, embed_model=embed_model, eval_qa=eval_qa, is_hybrid=is_hybrid, is_rag=is_rag)\n",
        "\n",
        "evaluation_model_name = llm_evaluate.model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============= STATS ============\n",
            "n_questions: 3\n",
            "evaluation model: gpt-3.5-turbo\n",
            "============= MODELS ===========\n",
            "(hyb-gpt-3.5-turbo-text-embedding-3-large-128*8-rag) - avg time: 6.56s, avg faithf: 0.00, avg relev: 0.33 avg correct: 4.25\n",
            "(hyb-gpt-3.5-turbo-text-embedding-ada-002-128*8-rag) - avg time: 4.00s, avg faithf: 0.00, avg relev: 0.33 avg correct: 4.50\n",
            "(hyb-gpt-3.5-turbo-deepset/roberta-base-squad2-128*8-rag) - avg time: 4.23s, avg faithf: 0.00, avg relev: 0.33 avg correct: 4.50\n",
            "(vec-gpt-3.5-turbo-text-embedding-3-large-128*8-rag) - avg time: 6.06s, avg faithf: 1.00, avg relev: 0.00 avg correct: 4.67\n",
            "(vec-gpt-3.5-turbo-text-embedding-ada-002-128*8-rag) - avg time: 5.25s, avg faithf: 1.00, avg relev: 0.67 avg correct: 4.50\n",
            "(vec-gpt-3.5-turbo-deepset/roberta-base-squad2-128*8-rag) - avg time: 6.10s, avg faithf: 0.00, avg relev: 0.33 avg correct: 4.17\n",
            "(hyb-gpt-3.5-turbo-text-embedding-3-large-128*8) - avg time: 1.17s, avg faithf: 0.00, avg relev: 0.00 avg correct: -1.00\n",
            "============= QA ============\n",
            "========================================================\n",
            "---Q evaluated by gpt-3.5-turbo: Why use NoSQL instead of SQL? --- ref answer: They are designed to scale horizontally.\n",
            "===\n",
            "(hyb-gpt-3.5-turbo-text-embedding-3-large-128*8-rag): NoSQL databases are often chosen over SQL databases when dealing with unstructured or semi-structured data. They offer more flexibility in handling varying data types and structures, making them suitable for applications that require horizontal scalability and distributed data models. NoSQL databases are also preferred for real-time applications and scenarios that require rapid development and iteration.\n",
            "t=5.5130932331085205s f=False r=False c=(4.0, 'The generated answer provides relevant information about the differences between NoSQL and SQL databases, highlighting the benefits of NoSQL in handling unstructured data and scalability. It aligns well with the user query and offers a comprehensive explanation.')\n",
            "sources: ['14-user-management/6-logout.mdx', 'changelog.mdx', '34-web-security-basics/4-injection-flaws.mdx', '24-introduction-to-svelte/6-svelte-in-a-container.mdx', '20-application-containerization/5-database-migrations.mdx', '36-other-frameworks-and-languages/3-python-and-fastapi.mdx', '21-working-with-databases/3-user-specific-data.mdx']\n",
            "===\n",
            "(hyb-gpt-3.5-turbo-text-embedding-ada-002-128*8-rag): NoSQL databases are often chosen over SQL databases when dealing with unstructured or semi-structured data, as they offer more flexibility in handling varying data types and structures. NoSQL databases are also preferred for their scalability and ability to handle large volumes of data efficiently, making them suitable for applications with high data variability and volume.\n",
            "t=4.574908494949341s f=False r=False c=None\n",
            "sources: ['14-user-management/6-logout.mdx', 'changelog.mdx', '34-web-security-basics/4-injection-flaws.mdx', '24-introduction-to-svelte/6-svelte-in-a-container.mdx', '20-application-containerization/5-database-migrations.mdx', '36-other-frameworks-and-languages/3-python-and-fastapi.mdx', '21-working-with-databases/3-user-specific-data.mdx']\n",
            "===\n",
            "(hyb-gpt-3.5-turbo-deepset/roberta-base-squad2-128*8-rag): NoSQL databases are often chosen over SQL databases when dealing with unstructured or rapidly changing data. They offer more flexibility in handling different data types and structures. Additionally, NoSQL databases can scale horizontally more easily, making them suitable for applications with high volumes of data and traffic.\n",
            "t=4.613356351852417s f=False r=False c=(4.5, 'The generated answer provides a comprehensive explanation of the reasons for choosing NoSQL over SQL, including handling unstructured data, flexibility with data types, and scalability. It also specifically mentions the ability of NoSQL databases to scale horizontally, which directly addresses the user query. The answer is relevant, correct, and goes beyond the basic explanation, earning a high score.')\n",
            "sources: ['14-user-management/6-logout.mdx', 'changelog.mdx', '34-web-security-basics/4-injection-flaws.mdx', '24-introduction-to-svelte/6-svelte-in-a-container.mdx', '20-application-containerization/5-database-migrations.mdx', '36-other-frameworks-and-languages/3-python-and-fastapi.mdx', '21-working-with-databases/3-user-specific-data.mdx']\n",
            "===\n",
            "(vec-gpt-3.5-turbo-text-embedding-3-large-128*8-rag): NoSQL databases are often chosen over SQL databases for their flexibility in handling unstructured or semi-structured data, scalability, and ability to handle large volumes of data efficiently. NoSQL databases are particularly suitable for applications where the data structure is not clearly defined or may evolve over time, allowing for easier adaptation to changing data requirements. Additionally, NoSQL databases are commonly used in distributed systems and cloud environments due to their horizontal scalability and fault tolerance capabilities.\n",
            "t=6.369071006774902s f=True r=False c=(4.5, 'The generated answer provides a comprehensive explanation of the reasons why NoSQL is preferred over SQL, covering aspects such as flexibility, scalability, handling of unstructured data, and suitability for distributed systems and cloud environments. The answer is relevant, detailed, and accurate, earning a high score.')\n",
            "sources: ['6-data-on-server/2-key-value-stores.mdx', '36-other-frameworks-and-languages/4-node-and-expressjs.mdx']\n",
            "===\n",
            "(vec-gpt-3.5-turbo-text-embedding-ada-002-128*8-rag): NoSQL databases are often chosen over SQL databases due to concerns about scalability and the ability to handle large amounts of data. NoSQL databases are designed to scale horizontally and are schemaless, allowing for more flexibility in handling complex data models. Additionally, NoSQL databases offer features that were initially missing in relational databases, leading to their adoption in certain scenarios.\n",
            "t=5.4031243324279785s f=True r=True c=(4.5, 'The generated answer provides a detailed explanation of why NoSQL is chosen over SQL, mentioning concerns about scalability, handling large amounts of data, horizontal scaling, schemaless nature, flexibility in handling complex data models, and additional features offered by NoSQL databases. The answer is relevant, comprehensive, and accurate, earning a high score.')\n",
            "sources: ['21-working-with-databases/2-databases-and-web-applications.mdx', '19-evolution-of-web-development/3-rest-client-side-frameworks-and-containerization.mdx', '16-user-specific-data/1-overview.mdx', '21-working-with-databases/3-user-specific-data.mdx', '6-data-on-server/2-key-value-stores.mdx', '36-other-frameworks-and-languages/4-node-and-expressjs.mdx']\n",
            "===\n",
            "(vec-gpt-3.5-turbo-deepset/roberta-base-squad2-128*8-rag): NoSQL databases are often chosen over SQL databases for reasons such as their ability to handle unstructured or semi-structured data more efficiently, scalability for large amounts of data, flexibility in schema design, and better performance for certain types of applications like real-time analytics or content management systems.\n",
            "\n",
            "NoSQL databases are non-relational and do not require a fixed schema, allowing for flexible data models. SQL databases are relational and use structured query language for defining and manipulating data. NoSQL databases are horizontally scalable and can handle large amounts of unstructured data efficiently. SQL databases are vertically scalable and work well for complex queries and transactions. NoSQL databases are often used for big data and real-time applications, while SQL databases are commonly used in traditional business applications.\n",
            "t=8.553580522537231s f=False r=True c=(3.5, 'The generated answer provides a detailed comparison between NoSQL and SQL databases, highlighting the reasons why NoSQL is often chosen over SQL. It correctly mentions the ability of NoSQL databases to handle unstructured data efficiently and their scalability for large amounts of data. However, there are some inaccuracies in the comparison between NoSQL and SQL databases, such as the statement that SQL databases are vertically scalable and work well for complex queries and transactions. This is not entirely accurate as SQL databases can also be horizontally scaled.')\n",
            "sources: ['21-working-with-databases/images/connection-pool/database_personal_emotional_2.svg', '21-working-with-databases/images/connection-pool/database2_nonpersonal_nonemotional_1.svg', '21-working-with-databases/images/connection-pool/database2_personal_emotional_2.svg', '21-working-with-databases/images/connection-pool/database_personal_nonemotional_2.svg', '21-working-with-databases/images/connection-pool/database_personal_nonemotional_1.svg', '21-working-with-databases/images/db_images/database_personal_nonemotional_1.svg', '21-working-with-databases/images/db_images/database_personal_emotional_1.svg', '21-working-with-databases/images/db_images/database2_personal_nonemotional_1.svg']\n",
            "===\n",
            "(hyb-gpt-3.5-turbo-text-embedding-3-large-128*8): NoSQL databases are more flexible and scalable, making them better suited for handling large amounts of unstructured data and high traffic loads.\n",
            "t=1.04783296585083s f=False r=False c=None\n",
            "sources: []\n",
            "\n",
            "\n",
            "\n",
            "========================================================\n",
            "---Q evaluated by gpt-3.5-turbo: What is the difference between authentication and authorization? --- ref answer: The term authentication refers to identifying a user. The term authorization refers to the process of verifying that the user has the rights to perform the actions that the user is trying to perform.\n",
            "===\n",
            "(hyb-gpt-3.5-turbo-text-embedding-3-large-128*8-rag): Authentication is the process of verifying the identity of a user, ensuring that the user is who they claim to be. Authorization, on the other hand, is the process of determining what actions or resources a user is allowed to access after they have been authenticated. In simpler terms, authentication confirms identity, while authorization determines permissions and access rights.\n",
            "t=7.141713380813599s f=False r=True c=None\n",
            "sources: ['13-authentication-and-authorization/1-authentication.mdx', '31-client-side-authentication/3-json-web-tokens.mdx', '13-authentication-and-authorization/2-authorization.mdx', '31-client-side-authentication/2-token-based-authentication.mdx']\n",
            "===\n",
            "(hyb-gpt-3.5-turbo-text-embedding-ada-002-128*8-rag): Authentication is the process of verifying the identity of a user, ensuring that the user is who they claim to be. On the other hand, authorization is the process of determining what actions or resources a user is allowed to access after they have been authenticated. Authentication focuses on verifying identity, while authorization focuses on granting permissions based on that verified identity.\n",
            "t=4.72999382019043s f=False r=True c=(4.5, 'The generated answer provides a clear and accurate explanation of the difference between authentication and authorization, matching the user query. The answer is well-structured and covers all the key points effectively. The only minor improvement could be slightly more concise wording.')\n",
            "sources: ['13-authentication-and-authorization/1-authentication.mdx', '31-client-side-authentication/3-json-web-tokens.mdx', '13-authentication-and-authorization/2-authorization.mdx', '31-client-side-authentication/2-token-based-authentication.mdx']\n",
            "===\n",
            "(hyb-gpt-3.5-turbo-deepset/roberta-base-squad2-128*8-rag): Authentication is the process of verifying the identity of a user, ensuring that the user is who they claim to be. Authorization, on the other hand, is the process of determining what actions or resources a user is allowed to access after they have been authenticated.\n",
            "t=3.8838088512420654s f=False r=True c=None\n",
            "sources: ['13-authentication-and-authorization/1-authentication.mdx', '31-client-side-authentication/3-json-web-tokens.mdx', '13-authentication-and-authorization/2-authorization.mdx', '31-client-side-authentication/2-token-based-authentication.mdx']\n",
            "===\n",
            "(vec-gpt-3.5-turbo-text-embedding-3-large-128*8-rag): Authentication is the process of identifying a user, typically by verifying their identity through various means like passwords or biometrics. On the other hand, authorization is the process of determining what actions a user is allowed to perform and what resources they can access after they have been authenticated. In simpler terms, authentication confirms who you are, while authorization determines what you can do.\n",
            "t=4.977261066436768s f=True r=False c=(5.0, 'The generated answer provides a clear and accurate explanation of the difference between authentication and authorization, matching the user query and reference answer closely.')\n",
            "sources: ['13-authentication-and-authorization/1-authentication.mdx', '13-authentication-and-authorization/2-authorization.mdx', '13-authentication-and-authorization/index.mdx']\n",
            "===\n",
            "(vec-gpt-3.5-turbo-text-embedding-ada-002-128*8-rag): Authentication is the process of verifying a user's identity, typically through credentials like passwords. It confirms that the user is who they claim to be. On the other hand, authorization is the process of determining what actions a user is allowed to perform and what resources they can access after they have been authenticated. It focuses on defining access rights to specific resources within an application based on the user's identity and permissions.\n",
            "t=5.219336032867432s f=True r=False c=(4.5, 'The generated answer provides a clear and accurate explanation of the difference between authentication and authorization, covering all the key points mentioned in the reference answer. The answer is well-structured and provides additional details, enhancing the understanding of the concepts.')\n",
            "sources: ['13-authentication-and-authorization/1-authentication.mdx', '13-authentication-and-authorization/2-authorization.mdx']\n",
            "===\n",
            "(vec-gpt-3.5-turbo-deepset/roberta-base-squad2-128*8-rag): Authentication is the process of verifying the identity of a user, ensuring that the user is who they claim to be. It involves validating credentials such as usernames and passwords. On the other hand, authorization is the process of determining what actions a user is allowed to perform within a system or application after they have been authenticated. Authorization involves defining access levels and permissions for different users or user roles.\n",
            "t=4.353816270828247s f=False r=False c=(4.5, 'The generated answer provides a clear and accurate explanation of the difference between authentication and authorization, covering all the key points mentioned in the reference answer. The answer is well-structured and provides detailed information, making it a strong response.')\n",
            "sources: ['33-end-to-end-testing/4-writing-playwright-tests.mdx', '14-user-management/3-registration.mdx', '14-user-management/4-login.mdx', '20-application-containerization/5-database-migrations.mdx', '34-web-security-basics/5-cross-site-scripting.mdx', '13-authentication-and-authorization/1-authentication.mdx', '36-other-frameworks-and-languages/3-python-and-fastapi.mdx', '35-deployment-and-docker/1-building-the-application.mdx']\n",
            "===\n",
            "(hyb-gpt-3.5-turbo-text-embedding-3-large-128*8): Authentication is the process of verifying a user's identity, while authorization is the process of determining what actions a user is allowed to perform.\n",
            "t=1.427825689315796s f=False r=False c=None\n",
            "sources: []\n",
            "\n",
            "\n",
            "\n",
            "========================================================\n",
            "---Q evaluated by gpt-3.5-turbo: What is a UUID? --- ref answer: UUIDs are a common way of identifying resources. They are 128-bit numbers that are designed for being unique without central coordination (i.e. a service that would keep track of which identifier to assign next).\n",
            "===\n",
            "(hyb-gpt-3.5-turbo-text-embedding-3-large-128*8-rag): A UUID, or Universally Unique Identifier, is a 128-bit number used to uniquely identify information or entities in computer systems. It is typically represented as a 32-character hexadecimal string, often separated by hyphens for readability. UUIDs are generated in a way that makes them highly unlikely to be duplicated, making them suitable for use as identifiers across different systems without the need for centralized coordination.\n",
            "t=7.011162281036377s f=False r=False c=(4.5, 'The generated answer provides a comprehensive explanation of what a UUID is, covering its purpose, structure, generation process, and uniqueness. It is relevant to the user query and accurately describes the concept of UUIDs. The answer could be improved by being slightly more concise without losing any important information.')\n",
            "sources: ['28-cascading-style-sheets/7-style-libraries.mdx', '22-application-programming-interfaces/1-apis-and-json.mdx', '31-client-side-authentication/1-api-keys.mdx', '2-internet-and-http/1-introduction-to-the-internet.mdx', '20-application-containerization/2-dockerfile-and-docker-compose.mdx', '9-forms-and-data/4-post-redirect-get.mdx', '11-data-validation/2-introduction-to-zod.mdx', '40-javascript-primer/8-objects.mdx']\n",
            "===\n",
            "(hyb-gpt-3.5-turbo-text-embedding-ada-002-128*8-rag): A UUID is a universally unique identifier.\n",
            "t=2.70981764793396s f=False r=False c=(4.5, 'The generated answer is relevant and fully correct, providing a concise definition of a UUID that aligns well with the user query.')\n",
            "sources: ['28-cascading-style-sheets/7-style-libraries.mdx', '22-application-programming-interfaces/1-apis-and-json.mdx', '2-internet-and-http/1-introduction-to-the-internet.mdx', '20-application-containerization/2-dockerfile-and-docker-compose.mdx', '9-forms-and-data/4-post-redirect-get.mdx', '11-data-validation/2-introduction-to-zod.mdx', '40-javascript-primer/8-objects.mdx']\n",
            "===\n",
            "(hyb-gpt-3.5-turbo-deepset/roberta-base-squad2-128*8-rag): A UUID, or Universally Unique Identifier, is a 128-bit number used to uniquely identify information or entities in computer systems. It is typically represented as a 32-character hexadecimal string, often separated by hyphens for readability. UUIDs are generated in such a way that they are highly unlikely to be duplicated, making them suitable for use in various scenarios where unique identification is required.\n",
            "t=4.180063486099243s f=False r=False c=None\n",
            "sources: ['28-cascading-style-sheets/7-style-libraries.mdx', '22-application-programming-interfaces/1-apis-and-json.mdx', '2-internet-and-http/1-introduction-to-the-internet.mdx', '20-application-containerization/2-dockerfile-and-docker-compose.mdx', '9-forms-and-data/4-post-redirect-get.mdx', '11-data-validation/2-introduction-to-zod.mdx', '40-javascript-primer/8-objects.mdx']\n",
            "===\n",
            "(vec-gpt-3.5-turbo-text-embedding-3-large-128*8-rag): A UUID is a universally unique identifier, which is a 128-bit number used to uniquely identify information or entities in computer systems.\n",
            "t=6.81990385055542s f=True r=False c=(4.5, 'The generated answer provides a clear and accurate explanation of what a UUID is, matching the reference answer closely. However, it could be improved by providing a bit more detail on how UUIDs are designed to be unique without central coordination.')\n",
            "sources: ['21-working-with-databases/images/db_images/database2_nonpersonal_nonemotional_2.svg', '21-working-with-databases/images/db_images/database2_personal_nonemotional_2.svg', '21-working-with-databases/images/db_images/database_nonpersonal_nonemotional_1.svg', '21-working-with-databases/images/db_images/database_personal_nonemotional_1.svg', '36-other-frameworks-and-languages/2-java-and-spring-boot.mdx']\n",
            "===\n",
            "(vec-gpt-3.5-turbo-text-embedding-ada-002-128*8-rag): A UUID is a 128-bit number that serves as a unique identifier for resources. It is designed to be unique without requiring central coordination, meaning there is no need for a service to keep track of which identifier to assign next. UUIDs are standardized in RFC 4122 and are commonly used for identifying objects or entities in various systems.\n",
            "t=5.122918605804443s f=True r=True c=None\n",
            "sources: ['2-internet-and-http/1-introduction-to-the-internet.mdx', '22-application-programming-interfaces/5-api-comprehension.mdx', '99-requesting-credits/2-requesting-grading.mdx', '10-the-crud/3-create.mdx', '12-cookies-and-sessions/5-sessions.mdx']\n",
            "===\n",
            "(vec-gpt-3.5-turbo-deepset/roberta-base-squad2-128*8-rag): A UUID, or Universally Unique Identifier, is a 128-bit number used to uniquely identify information or entities in computer systems. It is typically represented as a 32-character hexadecimal string, such as \"550e8400-e29b-41d4-a716-446655440000\". UUIDs are generated in a way that ensures uniqueness across space and time, making them suitable for identifying various types of data without the need for a centralized authority to coordinate the generation process.\n",
            "t=5.386519908905029s f=False r=False c=(4.5, 'The generated answer provides a detailed explanation of what a UUID is, including its format and purpose, which is accurate and relevant to the user query. The answer also correctly explains how UUIDs are generated and their uniqueness properties. However, the answer could be improved by being more concise and structured.')\n",
            "sources: ['12-cookies-and-sessions/index.mdx', '20-application-containerization/5-database-migrations.mdx', '34-web-security-basics/5-cross-site-scripting.mdx', '36-other-frameworks-and-languages/3-python-and-fastapi.mdx', '21-working-with-databases/3-user-specific-data.mdx', '6-data-on-server/index.mdx', '22-application-programming-interfaces/3-restful-apis.mdx', '36-other-frameworks-and-languages/4-node-and-expressjs.mdx']\n",
            "===\n",
            "(hyb-gpt-3.5-turbo-text-embedding-3-large-128*8): A UUID (Universally Unique Identifier) is a 128-bit number used to uniquely identify information in computer systems, ensuring no two items have the same identifier.\n",
            "t=1.0437908172607422s f=False r=False c=None\n",
            "sources: []\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"============= STATS ============\")\n",
        "print(f\"n_questions: {len(eval_qa)}\")\n",
        "print(f\"evaluation model: {evaluation_model_name}\")\n",
        "print(\"============= MODELS ===========\")\n",
        "\n",
        "for config_i, (chunk_size, similarity_top_k, is_hybrid, llm, is_rag, embed_model) in enumerate(config_lst):\n",
        "    time_avg = mean(time_scores[config_i])\n",
        "    faithfulness_avg = mean(faithfulness_scores[config_i])\n",
        "    relevancy_avg = mean(relevancy_scores[config_i])\n",
        "    correctness_without_none = [\n",
        "        x for x in correctness_scores[config_i] if x is not None]\n",
        "    correctness_avg = sum(\n",
        "        elt[0] for elt in correctness_without_none)/len(correctness_without_none) if len(correctness_without_none) > 0 else -1\n",
        "    print(\n",
        "        f\"({'hyb' if is_hybrid else 'vec'}-{llm.model}-{embed_model.model_name}-{chunk_size}*{similarity_top_k}{'-rag' if is_rag else ''}) - avg time: {time_avg:.2f}s, avg faithf: {faithfulness_avg:.2f}, avg relev: {relevancy_avg:.2f} avg correct: {correctness_avg:.2f}\")\n",
        "\n",
        "\n",
        "print(\"============= QA ============\")\n",
        "\n",
        "for i, (q, a) in enumerate(eval_qa):\n",
        "    print(\"========================================================\")\n",
        "    print(\n",
        "        f\"---Q evaluated by {evaluation_model_name}: {q} --- ref answer: {a}\")\n",
        "    for config_i, (chunk_size, similarity_top_k, is_hybrid, llm, is_rag, embed_model) in enumerate(config_lst):\n",
        "        print(\"===\")\n",
        "        print(\n",
        "            f\"({'hyb' if is_hybrid else 'vec'}-{llm.model}-{embed_model.model_name}-{chunk_size}*{similarity_top_k}{'-rag' if is_rag else ''}): {answers[config_i][i]}\")\n",
        "        print(\n",
        "            f\"t={time_scores[config_i][i]}s f={faithfulness_scores[config_i][i]} r={relevancy_scores[config_i][i]} c={correctness_scores[config_i][i]}\")\n",
        "        print(\n",
        "            f\"sources: {sources[config_i][i]}\")\n",
        "    print()\n",
        "    print()\n",
        "    print()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.11.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
